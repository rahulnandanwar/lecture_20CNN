{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 836
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 55559,
     "status": "ok",
     "timestamp": 1592846249811,
     "user": {
      "displayName": "Rahul Nandanwar",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgzzdR9Am4eo47Z0bK_GealsslMtZN4kMTuCCrQ=s64",
      "userId": "17908497525635550506"
     },
     "user_tz": -330
    },
    "id": "SqR48YITNfIR",
    "outputId": "0742026e-c10a-44b6-c191-7b156a2f4b69"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow==1.14\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/de/f0/96fb2e0412ae9692dbf400e5b04432885f677ad6241c088ccc5fe7724d69/tensorflow-1.14.0-cp36-cp36m-manylinux1_x86_64.whl (109.2MB)\n",
      "\u001b[K     |████████████████████████████████| 109.2MB 84kB/s \n",
      "\u001b[?25hRequirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14) (1.12.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14) (0.2.0)\n",
      "Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14) (1.0.8)\n",
      "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14) (1.1.2)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14) (1.1.0)\n",
      "Collecting tensorboard<1.15.0,>=1.14.0\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/91/2d/2ed263449a078cd9c8a9ba50ebd50123adf1f8cfbea1492f9084169b89d9/tensorboard-1.14.0-py3-none-any.whl (3.1MB)\n",
      "\u001b[K     |████████████████████████████████| 3.2MB 39.9MB/s \n",
      "\u001b[?25hRequirement already satisfied: numpy<2.0,>=1.14.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14) (1.18.5)\n",
      "Collecting tensorflow-estimator<1.15.0rc0,>=1.14.0rc0\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/3c/d5/21860a5b11caf0678fbc8319341b0ae21a07156911132e0e71bffed0510d/tensorflow_estimator-1.14.0-py2.py3-none-any.whl (488kB)\n",
      "\u001b[K     |████████████████████████████████| 491kB 43.5MB/s \n",
      "\u001b[?25hRequirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14) (0.34.2)\n",
      "Requirement already satisfied: gast>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14) (0.3.3)\n",
      "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14) (1.12.1)\n",
      "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14) (3.10.0)\n",
      "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14) (1.29.0)\n",
      "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14) (0.8.1)\n",
      "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14) (0.9.0)\n",
      "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.6->tensorflow==1.14) (2.10.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow==1.14) (3.2.2)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow==1.14) (47.3.1)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow==1.14) (1.0.1)\n",
      "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from markdown>=2.6.8->tensorboard<1.15.0,>=1.14.0->tensorflow==1.14) (1.6.1)\n",
      "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<1.15.0,>=1.14.0->tensorflow==1.14) (3.1.0)\n",
      "Installing collected packages: tensorboard, tensorflow-estimator, tensorflow\n",
      "  Found existing installation: tensorboard 2.2.2\n",
      "    Uninstalling tensorboard-2.2.2:\n",
      "      Successfully uninstalled tensorboard-2.2.2\n",
      "  Found existing installation: tensorflow-estimator 2.2.0\n",
      "    Uninstalling tensorflow-estimator-2.2.0:\n",
      "      Successfully uninstalled tensorflow-estimator-2.2.0\n",
      "  Found existing installation: tensorflow 2.2.0\n",
      "    Uninstalling tensorflow-2.2.0:\n",
      "      Successfully uninstalled tensorflow-2.2.0\n",
      "Successfully installed tensorboard-1.14.0 tensorflow-1.14.0 tensorflow-estimator-1.14.0\n",
      "Requirement already satisfied: keras in /usr/local/lib/python3.6/dist-packages (2.3.1)\n",
      "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras) (2.10.0)\n",
      "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from keras) (3.13)\n",
      "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.6/dist-packages (from keras) (1.18.5)\n",
      "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.6/dist-packages (from keras) (1.4.1)\n",
      "Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from keras) (1.0.8)\n",
      "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from keras) (1.1.2)\n",
      "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from keras) (1.12.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow==1.14\n",
    "!pip install keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 462
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1992,
     "status": "ok",
     "timestamp": 1592847217469,
     "user": {
      "displayName": "Rahul Nandanwar",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgzzdR9Am4eo47Z0bK_GealsslMtZN4kMTuCCrQ=s64",
      "userId": "17908497525635550506"
     },
     "user_tz": -330
    },
    "id": "uSOagPiJNqU8",
    "outputId": "864fdda6-d314-4b10-e958-4c63dce1cfd0"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "#import keras\n",
    "#import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Dropout, Flatten,Conv2D, MaxPooling2D\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "import numpy as np\n",
    "np.random.seed(1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2889,
     "status": "ok",
     "timestamp": 1592847218658,
     "user": {
      "displayName": "Rahul Nandanwar",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgzzdR9Am4eo47Z0bK_GealsslMtZN4kMTuCCrQ=s64",
      "userId": "17908497525635550506"
     },
     "user_tz": -330
    },
    "id": "Cj5m41SqQz5A",
    "outputId": "a4bd4f54-34d9-4097-f56a-984d7808cf2a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4070: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 73, 73, 96)        34944     \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 73, 73, 96)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 36, 36, 96)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 36, 36, 96)        384       \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 26, 26, 256)       2973952   \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 26, 26, 256)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 13, 13, 256)       0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 13, 13, 256)       1024      \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 11, 11, 384)       885120    \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 11, 11, 384)       0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 11, 11, 384)       1536      \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 9, 9, 384)         1327488   \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 9, 9, 384)         0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 9, 9, 384)         1536      \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 7, 7, 256)         884992    \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 7, 7, 256)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 3, 3, 256)         0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 3, 3, 256)         1024      \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 2304)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 4096)              9441280   \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_6 (Batch (None, 4096)              16384     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 4096)              16781312  \n",
      "_________________________________________________________________\n",
      "activation_7 (Activation)    (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_7 (Batch (None, 4096)              16384     \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1000)              4097000   \n",
      "_________________________________________________________________\n",
      "activation_8 (Activation)    (None, 1000)              0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 1000)              0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_8 (Batch (None, 1000)              4000      \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 9)                 9009      \n",
      "_________________________________________________________________\n",
      "activation_9 (Activation)    (None, 9)                 0         \n",
      "=================================================================\n",
      "Total params: 36,477,369\n",
      "Trainable params: 36,456,233\n",
      "Non-trainable params: 21,136\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "classifier = Sequential()\n",
    "\n",
    "# 1st Convolutional Layer\n",
    "classifier.add(Conv2D(filters=96, input_shape=(300,300,3), kernel_size=(11,11),strides=(4,4), padding='valid'))\n",
    "classifier.add(Activation('relu'))\n",
    "\n",
    "# Pooling \n",
    "classifier.add(MaxPooling2D(pool_size=(2,2), strides=(2,2), padding='valid'))\n",
    "\n",
    "# Batch Normalisation before passing it to the next layer\n",
    "classifier.add(BatchNormalization())\n",
    "\n",
    "# 2nd Convolutional Layer\n",
    "classifier.add(Conv2D(filters=256, kernel_size=(11,11), strides=(1,1), padding='valid'))\n",
    "classifier.add(Activation('relu'))\n",
    "\n",
    "# Pooling\n",
    "classifier.add(MaxPooling2D(pool_size=(2,2), strides=(2,2), padding='valid'))\n",
    "\n",
    "# Batch Normalisation\n",
    "classifier.add(BatchNormalization())\n",
    "\n",
    "# 3rd Convolutional Layer\n",
    "classifier.add(Conv2D(filters=384, kernel_size=(3,3), strides=(1,1), padding='valid'))\n",
    "classifier.add(Activation('relu'))\n",
    "\n",
    "# Batch Normalisation\n",
    "classifier.add(BatchNormalization())\n",
    "\n",
    "# 4th Convolutional Layer\n",
    "classifier.add(Conv2D(filters=384, kernel_size=(3,3), strides=(1,1), padding='valid'))\n",
    "classifier.add(Activation('relu'))\n",
    "\n",
    "# Batch Normalisation\n",
    "classifier.add(BatchNormalization())\n",
    "\n",
    "# 5th Convolutional Layer\n",
    "classifier.add(Conv2D(filters=256, kernel_size=(3,3), strides=(1,1), padding='valid'))\n",
    "classifier.add(Activation('relu'))\n",
    "\n",
    "# Pooling\n",
    "classifier.add(MaxPooling2D(pool_size=(2,2), strides=(2,2), padding='valid'))\n",
    "\n",
    "# Batch Normalisation\n",
    "classifier.add(BatchNormalization())\n",
    "\n",
    "# Passing it to a dense layer\n",
    "classifier.add(Flatten())\n",
    "\n",
    "# 1st Dense Layer\n",
    "classifier.add(Dense(4096, input_shape=(300, 300, 3)))\n",
    "classifier.add(Activation('relu'))\n",
    "\n",
    "# Add Dropout to prevent overfitting\n",
    "classifier.add(Dropout(0.4))\n",
    "\n",
    "# Batch Normalisation\n",
    "classifier.add(BatchNormalization())\n",
    "\n",
    "# 2nd Dense Layer\n",
    "classifier.add(Dense(4096))\n",
    "classifier.add(Activation('relu'))\n",
    "\n",
    "# Add Dropout\n",
    "classifier.add(Dropout(0.4))\n",
    "\n",
    "# Batch Normalisation\n",
    "classifier.add(BatchNormalization())\n",
    "\n",
    "# 3rd Dense Layer\n",
    "classifier.add(Dense(1000))\n",
    "classifier.add(Activation('relu'))\n",
    "\n",
    "# Add Dropout\n",
    "classifier.add(Dropout(0.4))\n",
    "\n",
    "# Batch Normalisation\n",
    "classifier.add(BatchNormalization())\n",
    "\n",
    "# Output Layer\n",
    "classifier.add(Dense(9))\n",
    "classifier.add(Activation('softmax'))\n",
    "classifier.summary()\n",
    "\n",
    "#Compile \n",
    "classifier.compile(loss='sparse_categorical_crossentropy', optimizer='adam',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2680,
     "status": "ok",
     "timestamp": 1592847218660,
     "user": {
      "displayName": "Rahul Nandanwar",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgzzdR9Am4eo47Z0bK_GealsslMtZN4kMTuCCrQ=s64",
      "userId": "17908497525635550506"
     },
     "user_tz": -330
    },
    "id": "NbJ-m2bXOZ-J"
   },
   "outputs": [],
   "source": [
    "# Part 2 - Fitting the CNN to the images\n",
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "train_datagen = ImageDataGenerator(rescale = 1./255,\n",
    "                                   shear_range = 0.2,\n",
    "                                   zoom_range = 0.2,\n",
    "                                   horizontal_flip = True)\n",
    "test_datagen = ImageDataGenerator(rescale = 1./255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2458,
     "status": "ok",
     "timestamp": 1592847218661,
     "user": {
      "displayName": "Rahul Nandanwar",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgzzdR9Am4eo47Z0bK_GealsslMtZN4kMTuCCrQ=s64",
      "userId": "17908497525635550506"
     },
     "user_tz": -330
    },
    "id": "ex4mcQteOgDN",
    "outputId": "3054c067-8587-46f6-d93f-d9040c723195"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 111 images belonging to 9 classes.\n",
      "Found 111 images belonging to 9 classes.\n"
     ]
    }
   ],
   "source": [
    "training_set = train_datagen.flow_from_directory('/content/drive/My Drive/FamilyClassifierData',\n",
    "                                                 target_size = (300, 300),\n",
    "                                                 batch_size = 32,\n",
    "                                                 class_mode = 'binary')\n",
    "\n",
    "test_set = test_datagen.flow_from_directory('/content/drive/My Drive/FamilyClassifierData',\n",
    "                                            target_size = (300, 300),\n",
    "                                            batch_size = 32,\n",
    "                                            class_mode = 'binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2227,
     "status": "ok",
     "timestamp": 1592847218662,
     "user": {
      "displayName": "Rahul Nandanwar",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgzzdR9Am4eo47Z0bK_GealsslMtZN4kMTuCCrQ=s64",
      "userId": "17908497525635550506"
     },
     "user_tz": -330
    },
    "id": "gOS_8-4mOiWV",
    "outputId": "b64cf2e6-9155-4bc4-964b-37d98b706a92"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.preprocessing.image.DirectoryIterator at 0x7f58e1afdd30>"
      ]
     },
     "execution_count": 7,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 170
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1984,
     "status": "ok",
     "timestamp": 1592847218663,
     "user": {
      "displayName": "Rahul Nandanwar",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgzzdR9Am4eo47Z0bK_GealsslMtZN4kMTuCCrQ=s64",
      "userId": "17908497525635550506"
     },
     "user_tz": -330
    },
    "id": "OaFonz_TOl4t",
    "outputId": "158d767c-4ff6-4d1d-91e5-41619269f5b9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Alexa': 0,\n",
       " 'Anup Varadkar': 1,\n",
       " 'Mug': 2,\n",
       " 'Papa': 3,\n",
       " 'Pradip Shirke': 4,\n",
       " 'Rahul Nandanwar': 5,\n",
       " 'Shubham Nandanwar': 6,\n",
       " 'Tejas Patil': 7,\n",
       " 'mummy': 8}"
      ]
     },
     "execution_count": 8,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_set.class_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 751
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 8070554,
     "status": "ok",
     "timestamp": 1592855287578,
     "user": {
      "displayName": "Rahul Nandanwar",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgzzdR9Am4eo47Z0bK_GealsslMtZN4kMTuCCrQ=s64",
      "userId": "17908497525635550506"
     },
     "user_tz": -330
    },
    "id": "3OJgWfbSOn4k",
    "outputId": "82e93a9c-2e32-4b3c-a473-3a1e58cdda8a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "Epoch 1/20\n",
      "25/25 [==============================] - 417s 17s/step - loss: 1.5604 - accuracy: 0.5358 - val_loss: 779.9242 - val_accuracy: 0.1622\n",
      "Epoch 2/20\n",
      "25/25 [==============================] - 396s 16s/step - loss: 0.7145 - accuracy: 0.7900 - val_loss: 386.3515 - val_accuracy: 0.1441\n",
      "Epoch 3/20\n",
      "25/25 [==============================] - 400s 16s/step - loss: 0.5528 - accuracy: 0.8352 - val_loss: 85.8565 - val_accuracy: 0.1622\n",
      "Epoch 4/20\n",
      "25/25 [==============================] - 413s 17s/step - loss: 0.3291 - accuracy: 0.8840 - val_loss: 32.1151 - val_accuracy: 0.2703\n",
      "Epoch 5/20\n",
      "25/25 [==============================] - 400s 16s/step - loss: 0.2391 - accuracy: 0.9241 - val_loss: 8.1272 - val_accuracy: 0.4324\n",
      "Epoch 6/20\n",
      "25/25 [==============================] - 393s 16s/step - loss: 0.3341 - accuracy: 0.9119 - val_loss: 16.8101 - val_accuracy: 0.3333\n",
      "Epoch 7/20\n",
      "25/25 [==============================] - 401s 16s/step - loss: 0.2532 - accuracy: 0.9284 - val_loss: 7.3734 - val_accuracy: 0.4685\n",
      "Epoch 8/20\n",
      "25/25 [==============================] - 413s 17s/step - loss: 0.1893 - accuracy: 0.9370 - val_loss: 0.0559 - val_accuracy: 0.8468\n",
      "Epoch 9/20\n",
      "25/25 [==============================] - 399s 16s/step - loss: 0.1701 - accuracy: 0.9513 - val_loss: 1.1709 - val_accuracy: 0.9009\n",
      "Epoch 10/20\n",
      "25/25 [==============================] - 395s 16s/step - loss: 0.1179 - accuracy: 0.9574 - val_loss: 0.0093 - val_accuracy: 0.9459\n",
      "Epoch 11/20\n",
      "25/25 [==============================] - 399s 16s/step - loss: 0.1520 - accuracy: 0.9670 - val_loss: 2.2533 - val_accuracy: 0.6937\n",
      "Epoch 12/20\n",
      "25/25 [==============================] - 411s 16s/step - loss: 0.1382 - accuracy: 0.9556 - val_loss: 1.4933 - val_accuracy: 0.8288\n",
      "Epoch 13/20\n",
      "25/25 [==============================] - 400s 16s/step - loss: 0.0922 - accuracy: 0.9685 - val_loss: 0.5091 - val_accuracy: 0.8468\n",
      "Epoch 14/20\n",
      "25/25 [==============================] - 400s 16s/step - loss: 0.0863 - accuracy: 0.9742 - val_loss: 0.6148 - val_accuracy: 0.9009\n",
      "Epoch 15/20\n",
      "25/25 [==============================] - 394s 16s/step - loss: 0.0918 - accuracy: 0.9750 - val_loss: 0.9084 - val_accuracy: 0.7387\n",
      "Epoch 16/20\n",
      "25/25 [==============================] - 414s 17s/step - loss: 0.1445 - accuracy: 0.9513 - val_loss: 2.1713 - val_accuracy: 0.8468\n",
      "Epoch 17/20\n",
      "25/25 [==============================] - 396s 16s/step - loss: 0.1198 - accuracy: 0.9618 - val_loss: 0.0090 - val_accuracy: 0.9910\n",
      "Epoch 18/20\n",
      "25/25 [==============================] - 414s 17s/step - loss: 0.0498 - accuracy: 0.9762 - val_loss: 0.4023 - val_accuracy: 0.9099\n",
      "Epoch 19/20\n",
      "25/25 [==============================] - 402s 16s/step - loss: 0.0885 - accuracy: 0.9699 - val_loss: 0.0051 - val_accuracy: 0.9910\n",
      "Epoch 20/20\n",
      "25/25 [==============================] - 407s 16s/step - loss: 0.1824 - accuracy: 0.9604 - val_loss: 0.0597 - val_accuracy: 0.9730\n"
     ]
    }
   ],
   "source": [
    "model = classifier.fit_generator(training_set, steps_per_epoch = 25, epochs = 20, validation_data = test_set, validation_steps = 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 8073071,
     "status": "ok",
     "timestamp": 1592855290613,
     "user": {
      "displayName": "Rahul Nandanwar",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgzzdR9Am4eo47Z0bK_GealsslMtZN4kMTuCCrQ=s64",
      "userId": "17908497525635550506"
     },
     "user_tz": -330
    },
    "id": "dCk-j58nOvZw",
    "outputId": "44b149f9-4b8a-4518-8fc9-fd60fadb72a1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model to disk\n"
     ]
    }
   ],
   "source": [
    "classifier.save(\"model_familyClassification_ResNet.h5\")\n",
    "print(\"Saved model to disk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wAb-spuWByCW"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from keras.preprocessing import image\n",
    "test_image = image.load_img(r'/content/drive/My Drive/FirstCNN_train_Data/Alexa/IMG_20200530_230047.jpg', target_size = (300, 300))\n",
    "test_image = image.img_to_array(test_image)\n",
    "test_image = np.expand_dims(test_image, axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BvqWr-JLBy6v"
   },
   "outputs": [],
   "source": [
    "result = classifier.predict(test_image)\n",
    "result = np.argmax(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "b0yVt8pqB1cI"
   },
   "outputs": [],
   "source": [
    "result"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyPZ7pAbkulsLc7hBe5aNAML",
   "mount_file_id": "1wf0n9FTHBVPUmoyvVb1TbcLuUQrPcEDZ",
   "name": "AlexNet CNN Network.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
